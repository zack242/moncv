{
    "personal": {
        "name": "Zakaria TOZY",
        "title": "Data Engineer",
        "phone": "0617407077",
        "email": "zakaria.tozy@icloud.com",
        "linkedin": "zakaria-tozy",
        "github": "github.com/zack242",
        "contract": "CDI",
        "location": "Paris",
        "summary": "Ingénieur en Systèmes d'Information et Data Science avec une double formation (ECE Paris/Polytechnique), passionné par la data et les nouvelles technologies. Je recherche un poste en CDI pour contribuer à des projets innovants et à forte valeur ajoutée."
    },
    "skills": {
        "programming": [
            "Python",
            "SQL",
            "Java",
            "C++",
            "C#"
        ],
        "languages": [
            "Français (Bilingue)",
            "Arabe (Bilingue)",
            "Anglais (Courant - TOEIC 875)"
        ],
        "data_engineering": [
            "PySpark",
            "BigQuery",
            "ETL",
            "Data Pipelines"
        ],
        "cloud_databases": [
            "Databricks",
            "Snowflake",
            "GCP",
            "dbt"
        ],
        "machine_learning": [
            "Scikit-Learn",
            "NLP",
            "Computer Vision",
            "Deep Learning"
        ],
        "devops": [
            "Docker",
            "CI/CD",
            "Git",
            "Scrum"
        ],
        "soft_skills": [
            "Autonomie",
            "Rigueur",
            "Esprit d'analyse",
            "Apprentissage rapide"
        ]
    },
    "education": [
        {
            "school": "École Centrale d'Électronique (ECE Paris)",
            "degree": "Ingénieur en Systèmes d'information et Big data analytics",
            "date": "Janv 2024",
            "distinction": "Top 5% de la promotion",
            "specialization": "Spécialisation : Programmation, Bases de données, Électronique, DevOps"
        },
        {
            "school": "Institut Polytechnique de Paris (Ecole polytechnique)",
            "degree": "Master 2 en Data Sciences",
            "date": "Janv 2024",
            "distinction": "Mention Très bien",
            "specialization": "Spécialisation : Machine Learning, Big Data, Cloud Infrastructure, Deep Learning, NLP"
        }
    ],
    "experience": [
        {
            "company": "AXA Investment Managers - AXA IM",
            "position": "Data Engineer/Data Analyst Intern",
            "dates": "Août 2023 -- Jan 2024",
            "highlights": [
                "Conception et mise en place d'une dizaine de pipelines ETL pour l'ingestion de données métiers.",
                "Optimisation du modèle de données et migration des pipelines de distribution utilisés pour le reporting financier de 844 milliards d'euros d'actifs en 2023.",
                "Tests de nouveaux clusters sur Databricks et création d'un PoC pour l'anonymisation des données sensibles.",
                "Création de tableaux de bord pour les contrôleurs financiers, facilitant leur accès aux données.",
                "Calcul des indicateurs de performance KPIs pour la vision distribuée (ME, OV, CIS, FX)."
            ]
        },
        {
            "company": "Kalima Blockchain et IoT",
            "position": "Software Engineer Intern",
            "dates": "Avr 2022 -- Août 2022",
            "highlights": [
                "Développement d'un explorateur de blockchain en Java/LevelDB (+1000 transactions par seconde).",
                "Implémentation de nouvelles fonctionnalités d'administration pour la blockchain Kalima en Node.js.",
                "Conception et développement d'un système d'authentification multisignature pour les DApps."
            ]
        },
        {
            "company": "Le Crédit Lyonnais - LCL",
            "position": "IT Intern",
            "dates": "Janv 2020 -- Fév 2020",
            "highlights": [
                "Étude de migration Office 2010 vers 2016 et analyse d'impact sur les processus métiers.",
                "Développement et exécution de procédures de tests sur un parc de 23 000 postes."
            ]
        }
    ],
    "projects": [
        {
            "name": "Bitcoin Analysis - Data Pipeline",
            "highlights": [
                "Création d'un pipeline de données avec Python, SQL, Airflow, dbt et Snowflake pour l'analyse des transactions Bitcoin, traitant plus de 1 million de transactions par jour."
            ]
        },
        {
            "name": "Twitter Real-time Analysis",
            "highlights": [
                "Développement d'un système de visualisation en temps réel des flux Twitter par topics à l'aide de Kafka et de l'algorithme KNN."
            ]
        },
        {
            "name": "Energy Disaggregation @ Capgemini",
            "highlights": [
                "Extraction de la composante thermosensible de la consommation énergétique pour prévoir la demande future en France."
            ]
        }
    ]
}